{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DataSciToolbox**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Introducción      "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bienvenido/a a *DataSciToolbox*\n",
    "\n",
    "Le damos la bienvenida a la biblioteca de funciones en Python orientadas a *machine learning*, recopilada por los alumnos de la promoción de abril a agosto de 2023 del bootcamp de Data Science de **The Bridge, Digital Talent Accelerator**.\n",
    "\n",
    "En ella, encontrará un extensivo repositorio que abarca todas las fases necesarias para afrontar un proyecto de *machine learning*, desde el análisis exploratorio de datos hasta la evaluación de los modelos, pasando por las etapas de preprocesamiento, visualización, *feature engineering* o entrenamiento y evaluación de los modelos.\n",
    "\n",
    "Esperamos que le sea de utilidad. *Happy coding!*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"0\"></a> <br>\n",
    "## Índice:\n",
    "* [Instalación](#2)\n",
    "* [Funciones](#3)\n",
    "    * [Funciones de Preprocesado de datos](#4)\n",
    "        * [Class ReduceMemory](#5)\n",
    "        * [leer_csv_desde_rar](#6)\n",
    "        * [leer_csv_desde_zip](#7)\n",
    "        * [tratar_valores_nulos](#8)\n",
    "        * [split_and_encode_strings](#9)\n",
    "        * [segmentar_y_guardar](#10)\n",
    "        * [calcular_edad](#11)\n",
    "        * [obtener_hora_minuto_segundo](#12)\n",
    "        * [eliminar_unidades_metricas](#13)\n",
    "        * [cambiar_nombres_columnas](#14)\n",
    "        * [create_dataframe_yahoo_finance](#15)\n",
    "        * [limpiar_columnas_numericas](#16)\n",
    "        * [encoding_proporcional_target_binaria](#17)\n",
    "        * [eliminacion_outliers](#18)\n",
    "        * [comprobacion_outliers](#19)\n",
    "    * [Funciones de Modelado](#150)\n",
    "        * [evaluacion_clas](#20)\n",
    "        * [modelo_kmeans_df](#21)\n",
    "        * [evaluacion_reg](#22)\n",
    "        * [train_decision_tree](#23)\n",
    "        * [train_knn](#24)\n",
    "        * [train_linear_regression](#25)\n",
    "        * [train_random_forest](#26)\n",
    "        * [train_svr](#27)\n",
    "        * [train_test_split_df](#28)\n",
    "        * [balance_target_column_random](#29)\n",
    "        * [balance_target_column_smote](#30)\n",
    "        * [reductor_calidad](#31)\n",
    "        * [ByN](#32)\n",
    "        * [comparar_modelos](#33)\n",
    "        * [export_import_model](#34)\n",
    "        * [comparar_scaled](#35)\n",
    "    * [Funciones de Visualizaciones](#200)\n",
    "        * [plot_moving_averages](#36)\n",
    "        * [plot_pca_importance](#37)\n",
    "        * [plot_pca_importance_agg](#38)\n",
    "        * [plot_scatter_with_reference](#39)\n",
    "        * [plot_learning_curve](#40)\n",
    "        * [plot_precision_recall_curve](#41)\n",
    "        * [plot_roc_curve](#42)\n",
    "        * [dist_variables](#43)\n",
    "        * [plot_correlations](#44)\n",
    "        * [plot_map](#45)\n",
    "        * [plot_wordcloud](#46)\n",
    "        * [plot_quality_counts](#47)\n",
    "        * [plot_heatmap](#48)\n",
    "        * [plot_data](#49)\n",
    "        \n",
    "* [Conclusiones](#250)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a> <br>\n",
    "### Instalación    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procesos de instalacion...pip install etc...  \n",
    "Estamos en proceso de construcción de la libreria.\n",
    "\n",
    "![En obras](obras.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a> <br>\n",
    "### *Funciones*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el ámbito del análisis de datos y el aprendizaje automático, las funciones desempeñan un papel crucial para lograr resultados precisos y significativos. Estas funciones abarcan diferentes aspectos, incluyendo el procesamiento de datos, la modelización y la visualización.  \n",
    "\n",
    "En esta sección mostraremos todas las funciones de la biblioteca y explicaremos la utilidad de ellas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a> <br>\n",
    "### *Funciones de procesado de datos*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El procesamiento de datos es una etapa esencial en el flujo de trabajo de análisis de datos y aprendizaje automático. En esta fase, se aplican diversas funciones de procesado de datos para preparar y transformar los datos brutos en una forma adecuada para el análisis y la modelización.  \n",
    "A continuación se mostrarán todas las funciones de procesado de datos de esta biblioteca."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a> <br>\n",
    "##### Class ReduceMemory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta clase reduciremos el consumo de memoria.  \n",
    "\n",
    "Tenemos varios metodos dentro de la clase:\n",
    "- process --> Reduce el consumo de memoria de un DataFrame de Pandas aplicando reducciones de tipo de datos en cada columna del DataFrame.\n",
    "- reduce_object --> Reduce el consumo de memoria de una columna de tipo objeto (string) convirtiéndola a tipo entero.\n",
    "- reduce_float --> Reduce el consumo de memoria de una columna de tipo float ajustando su tipo de dato.\n",
    "- reduce_int --> Reduce el consumo de memoria de una columna de tipo entero ajustando su tipo de dato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReduceMemory:\n",
    "    \"\"\"\n",
    "    Clase para reducir el consumo de memoria de un DataFrame de Pandas\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.before_size = 0\n",
    "        self.after_size = 0\n",
    "\n",
    "    def process(self, data_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Reduce el consumo de memoria de un DataFrame de Pandas aplicando reducciones de \n",
    "        tipo de datos en cada columna del DataFrame.\n",
    "\n",
    "        Args:\n",
    "            data_df (pd.DataFrame): DataFrame de Pandas a procesar.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame de Pandas con el consumo de memoria reducido.\n",
    "        \"\"\"\n",
    "        cols = data_df.columns\n",
    "\n",
    "        for col in cols:\n",
    "            try:\n",
    "                dtype = data_df[col].dtype\n",
    "\n",
    "                if dtype == 'object':\n",
    "                    data_df[col] = self.reduce_object(data_df[col])\n",
    "                elif dtype == 'float':\n",
    "                    data_df[col] = self.reduce_float(data_df[col])\n",
    "                elif dtype == 'int':\n",
    "                    data_df[col] = self.reduce_int(data_df[col])\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing column '{col}': {str(e)}\")\n",
    "\n",
    "        return data_df\n",
    "\n",
    "    def reduce_object(self, data_serie: pd.Series) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Reduce el consumo de memoria de una columna de tipo objeto (string) convirtiéndola \n",
    "        a tipo entero.\n",
    "\n",
    "        Args:\n",
    "            data_serie (pd.Series): Columna de tipo objeto a procesar.\n",
    "\n",
    "        Returns:\n",
    "            pd.Series: Columna de tipo entero con el consumo de memoria reducido.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.before_size = round(sys.getsizeof(data_serie) / 1024 ** 2,2)\n",
    "                    \n",
    "            transformlabel = {v:k for k,v in enumerate(data_serie.unique())}\n",
    "            \n",
    "            data_serie = data_serie.map(transformlabel).astype('int8')\n",
    "\n",
    "            self.after_size = round(sys.getsizeof(data_serie) / 1024 ** 2,2)\n",
    "        \n",
    "            return data_serie\n",
    "        \n",
    "        except Exception as err:\n",
    "            print(f\"Error reducing object column: {str(err)}\")\n",
    "            return data_serie\n",
    "\n",
    "    def reduce_float(self, data_serie: pd.Series) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Reduce el consumo de memoria de una columna de tipo float ajustando su tipo de dato.\n",
    "\n",
    "        Args:\n",
    "            data_serie (pd.Series): Columna de tipo float a procesar.\n",
    "\n",
    "        Returns:\n",
    "            pd.Series: Columna con el tipo de dato ajustado y el consumo de memoria reducido.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.before_size = round(sys.getsizeof(data_serie) / 1024 ** 2,2)\n",
    "                    \n",
    "            min_value, max_value = data_serie.min(), data_serie.max()\n",
    "            \n",
    "            if min_value >= np.finfo('float16').min and max_value <= np.finfo('float16').max:\n",
    "                data_serie = data_serie.astype('float16')\n",
    "            elif min_value >= np.finfo('float32').min and max_value <= np.finfo('float32').max:\n",
    "                data_serie = data_serie.astype('float32')\n",
    "            else:\n",
    "                data_serie = data_serie.astype('float64')\n",
    "                \n",
    "            self.after_size = round(sys.getsizeof(data_serie) / 1024**2,2)\n",
    "\n",
    "            return data_serie\n",
    "        \n",
    "        except Exception as err:\n",
    "            print(f\"Error reducing float column: {str(err)}\")\n",
    "            return data_serie\n",
    "\n",
    "    def reduce_int(self, data_serie: pd.Series) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Reduce el consumo de memoria de una columna de tipo entero ajustando su tipo de dato.\n",
    "\n",
    "        Args:\n",
    "            data_serie (pd.Series): Columna de tipo entero a procesar.\n",
    "\n",
    "        Returns:\n",
    "            pd.Series: Columna con el tipo de dato ajustado y el consumo de memoria reducido.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.before_size = round(sys.getsizeof(data_serie) / 1024 ** 2,2)\n",
    "                    \n",
    "            min_value,max_value = data_serie.min(), data_serie.max()\n",
    "            \n",
    "            if min_value >= np.iinfo('int8').min and max_value <= np.iinfo('int8').max:\n",
    "                data_serie = data_serie.astype('int8')\n",
    "            if min_value >= np.iinfo('int16').min and max_value <= np.iinfo('int16').max:\n",
    "                data_serie = data_serie.astype('int16')\n",
    "            elif min_value >= np.iinfo('int32').min and max_value <= np.iinfo('int32').max:\n",
    "                data_serie = data_serie.astype('int32')\n",
    "            else:\n",
    "                data_serie = data_serie.astype('int64')\n",
    "                \n",
    "            self.after_size = round(sys.getsizeof(data_serie) / 1024**2,2)\n",
    "\n",
    "            return data_serie\n",
    "        \n",
    "        except Exception as err:\n",
    "            print(f\"Error reducing int column: {str(err)}\")\n",
    "\n",
    "            return data_serie      "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a> <br>\n",
    "##### leer_csv_desde_rar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lee un archivo CSV desde un archivo .rar.  \n",
    "Con esto nos evitaremos problemas a la hora de leer csv pesados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leer_csv_desde_rar(ruta_archivo:str, nombre_archivo_csv:str) -> pd.DataFrame:\n",
    "    \n",
    "    \"\"\"\n",
    "        Lee un archivo CSV desde un archivo .rar.\n",
    "\n",
    "    Args:\n",
    "        ruta_archivo (str): La ruta del archivo .rar.\n",
    "        nombre_archivo_csv (str): El nombre del archivo CSV que se desea leer desde el .rar.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Los datos leídos del archivo CSV como un DataFrame de pandas.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        archivo_rar = rarfile.RarFile(ruta_archivo) # Abrir el archivo .rar\n",
    "        contenido_rar = archivo_rar.namelist() # Leer el contenido del archivo .rar\n",
    "        if nombre_archivo_csv in contenido_rar: # Verificar si el archivo CSV está presente en el .rar          \n",
    "            with archivo_rar.open(nombre_archivo_csv) as archivo_csv: # Leer el archivo CSV\n",
    "                datos = pd.read_csv(archivo_csv)\n",
    "                return datos\n",
    "        else:\n",
    "            print(\"El archivo CSV no se encuentra en el archivo .rar.\")\n",
    "            return None\n",
    "    except FileNotFoundError:\n",
    "        print(\"El archivo .rar no fue encontrado.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(\"Ocurrió un error al leer el archivo .rar:\", str(e))\n",
    "        return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a> <br>\n",
    "##### leer_csv_desde_zip"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lee un archivo CSV desde un archivo .zip.  \n",
    "Al igual que la función anterior, con esta función nos evitaremos problemas a la hora de leer csv pesados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leer_csv_desde_zip(ruta_archivo: str, nombre_archivo_csv: str)-> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Lee un archivo CSV desde un archivo .zip.\n",
    "\n",
    "    Args:\n",
    "        ruta_archivo (str): La ruta del archivo .zip.\n",
    "        nombre_archivo_csv (str): El nombre del archivo CSV que se desea leer desde el .zip.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Los datos leídos del archivo CSV como un DataFrame de pandas.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        archivo_zip = zipfile.ZipFile(ruta_archivo)  # Abrir el archivo .zip\n",
    "        contenido_zip = archivo_zip.namelist()  # Leer el contenido del archivo .zip\n",
    "        if nombre_archivo_csv in contenido_zip:  # Verificar si el archivo CSV está presente en el .zip\n",
    "            with archivo_zip.open(nombre_archivo_csv) as archivo_csv:  # Leer el archivo CSV\n",
    "                datos = pd.read_csv(archivo_csv)\n",
    "            return datos\n",
    "        else:\n",
    "            print(\"El archivo CSV no se encuentra en el archivo .zip.\")\n",
    "            return None\n",
    "    except FileNotFoundError:\n",
    "        print(\"El archivo .zip no fue encontrado.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(\"Ocurrió un error al leer el archivo .zip:\", str(e))\n",
    "        return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"8\"></a> <br>\n",
    "##### tratar_valores_nulos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta función lo que podemos conseguir es eliminar, rellenar de ceros o rellenar la media de los valores nulos que hay en un dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tratar_valores_nulos(dataframe:pd.DataFrame, opcion:str) -> Union[pd.DataFrame, None]:\n",
    "    \"\"\"\n",
    "    Trata los valores nulos en un DataFrame según la opción seleccionada.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): El DataFrame que se desea procesar.\n",
    "        opcion (str): La opción seleccionada para tratar los valores nulos.\n",
    "            Opciones disponibles: 'eliminar', 'rellenar_cero', 'rellenar_media'.\n",
    "\n",
    "    Returns:\n",
    "        Union[pd.DataFrame, None]: El DataFrame con los valores nulos tratados según la opción seleccionada.\n",
    "        En caso de error, retorna None.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if opcion == 'eliminar':\n",
    "            dataframe_sin_nulos = dataframe.dropna()\n",
    "            return dataframe_sin_nulos\n",
    "        elif opcion == 'rellenar_cero':\n",
    "            dataframe_rellenado = dataframe.fillna(0)\n",
    "            return dataframe_rellenado\n",
    "        elif opcion == 'rellenar_media':\n",
    "            dataframe_rellenado = dataframe.fillna(dataframe.mean())\n",
    "            return dataframe_rellenado\n",
    "        else:\n",
    "            print(\"Opción inválida. Las opciones disponibles son: 'eliminar', 'rellenar_cero', 'rellenar_media'.\")\n",
    "            return dataframe\n",
    "    except Exception as e:\n",
    "        print(\"Ocurrió un error al tratar los valores nulos:\", str(e))\n",
    "        return None\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"9\"></a> <br>\n",
    "##### split_and_encode_strings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separa una columna de un DataFrame utilizando cualquier carácter que no sea una letra o un número como separador, y opcionalmente aplica one-hot encoding (get dummies) a las palabras separadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_encode_strings(column:pd.Series, use_encoding: bool = False ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Separa una columna de un DataFrame utilizando cualquier carácter que no sea una letra o un número como separador,\n",
    "    y opcionalmente aplica one-hot encoding (get dummies) a las palabras separadas.\n",
    "\n",
    "    Args:\n",
    "        column (pd.Series): La columna del DataFrame que se desea separar y encodear.\n",
    "        use_encoding (bool, optional): Indica si se debe aplicar one-hot encoding a las palabras separadas.\n",
    "            Por defecto es False.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Un DataFrame con las palabras separadas en una sola columna si use_encoding es False,\n",
    "            o un DataFrame con columnas correspondientes a cada palabra si use_encoding es True.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        separador = re.compile(r'[^a-zA-Z0-9]+')\n",
    "        palabras = column.apply(lambda x: separador.split(x))\n",
    "        if use_encoding:\n",
    "            df = pd.get_dummies(palabras.apply(pd.Series).stack()).groupby(level=1).sum()\n",
    "        else:\n",
    "            df = pd.DataFrame(palabras)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(\"Ocurrió un error al separar y encodear las strings:\", str(e))\n",
    "        return None\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"10\"></a> <br>\n",
    "##### segmentar_y_guardar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmenta un DataFrame en varios segmentos y los guarda en archivos CSV.  \n",
    "A partir de un Dataframe dividimos en un número de segmentos concreto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentar_y_guardar(df: pd.DataFrame, num_segmentos:int, output_folder:str):\n",
    "    \"\"\"\n",
    "    Segmenta un DataFrame en varios segmentos y los guarda en archivos CSV.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame a segmentar.\n",
    "        num_segmentos (int): Número de segmentos en los que dividir el DataFrame.\n",
    "        output_folder (str): Ruta de la carpeta de salida para guardar los archivos CSV.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        segmentos = np.array_split(df, num_segmentos)\n",
    "\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "\n",
    "        for i, segmento in enumerate(segmentos):\n",
    "            segmento.to_csv(f'{output_folder}/segmento_{i+1}.csv', index=False)\n",
    "\n",
    "        print(f\"Se han creado {num_segmentos} archivos CSV segmentados en la carpeta '{output_folder}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al guardar los segmentos en archivos CSV: {str(e)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"11\"></a> <br>\n",
    "##### calcular_edad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta función calcula la edad a partir de la fecha de nacimiento en un DataFrame.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_edad(df: pd.DataFrame, columna_nacimiento: str, fecha_referencia: str = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calcula la edad a partir de la fecha de nacimiento en un DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): El DataFrame que contiene los datos.\n",
    "        columna_nacimiento (str): El nombre de la columna que contiene las fechas de nacimiento.\n",
    "        fecha_referencia (str, optional): La fecha de referencia para calcular la edad. Si no se proporciona,\n",
    "            se utilizará la fecha actual. Formato: 'YYYY-MM-DD'. Default: None.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Un nuevo DataFrame con una columna adicional \"edad\" que contiene las edades calculadas.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Si la columna de fecha de nacimiento no existe en el DataFrame.\n",
    "\n",
    "    Example:\n",
    "        # Cargar el DataFrame desde algún origen de datos\n",
    "        df = pd.read_csv(\"datos.csv\")\n",
    "\n",
    "        # Calcular la edad utilizando la función calcular_edad\n",
    "        df_con_edad = calcular_edad(df, \"dob\")\n",
    "\n",
    "        # Imprimir el DataFrame resultante con la columna \"edad\" agregada\n",
    "        print(df_con_edad)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if columna_nacimiento not in df.columns:\n",
    "            raise ValueError(f\"La columna '{columna_nacimiento}' no existe en el DataFrame.\")\n",
    "\n",
    "        df = df.copy()\n",
    "        df[columna_nacimiento] = pd.to_datetime(df[columna_nacimiento])\n",
    "\n",
    "        if fecha_referencia is None:\n",
    "            fecha_referencia = pd.to_datetime(\"today\").date()\n",
    "        else:\n",
    "            fecha_referencia = pd.to_datetime(fecha_referencia).date()\n",
    "\n",
    "        df[\"edad\"] = df[columna_nacimiento].apply(lambda x: relativedelta(fecha_referencia, x).years)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Ocurrió un error: {str(e)}\")\n",
    "        return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"12\"></a> <br>\n",
    "##### obtener_hora_minuto_segundo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos la hora, minuto y segundo en columnas separadas a partir de una columna de hora en un DataFrame.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_hora_minuto_segundo(df:pd.DataFrame, columna_hora:str):\n",
    "    \"\"\"\n",
    "    Calcula la hora, minuto y segundo en columnas separadas a partir de una columna de hora en un DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame que contiene la columna de hora.\n",
    "        columna_hora (str): Nombre de la columna que contiene la hora.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame con las columnas \"hora\", \"minuto\" y \"segundo\" agregadas. Si ocurre un error durante la conversión, se devuelve el DataFrame original sin modificaciones.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Si la columna de hora no se encuentra en el DataFrame.\n",
    "\n",
    "    Example:\n",
    "        df = pd.DataFrame({\"hora\": [\"08:30:45\", \"12:15:30\"]})\n",
    "        nuevo_df = obtener_hora_minuto_segundo(df, \"hora\")\n",
    "    \"\"\"\n",
    "    if columna_hora not in df.columns:\n",
    "        raise ValueError(f\"La columna '{columna_hora}' no se encuentra en el DataFrame.\")\n",
    "\n",
    "    try:\n",
    "        hora_dt = pd.to_datetime(df[columna_hora], format=\"%H:%M:%S\")\n",
    "        df[\"hora\"] = hora_dt.dt.hour\n",
    "        df[\"minuto\"] = hora_dt.dt.minute\n",
    "        df[\"segundo\"] = hora_dt.dt.second\n",
    "    except Exception as e:\n",
    "        print(\"Error al convertir la columna de hora:\", str(e))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"13\"></a> <br>\n",
    "##### eliminar_unidades_metricas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elimina las unidades métricas de una columna de un DataFrame y la convierte a tipo float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_unidades_metricas(df:pd.DataFrame, columna:str):\n",
    "    \"\"\"\n",
    "    Elimina las unidades métricas de una columna de un DataFrame y la convierte a tipo float.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): El DataFrame que contiene la columna con unidades métricas.\n",
    "        columna (str): El nombre de la columna a procesar.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: El DataFrame modificado con la unidad métrica eliminada y la columna convertida a tipo float.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        valores = df[columna].astype(str)\n",
    "        valores_sin_unidades = valores.apply(lambda x: re.sub(r'[a-zA-Z]+', '', x))\n",
    "        valores_sin_unidades = valores_sin_unidades.str.strip()\n",
    "        df[columna] = valores_sin_unidades.astype(float)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"14\"></a> <br>\n",
    "##### cambiar_nombres_columnas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta función podemos cambiar los nombre de las columnas de los dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cambiar_nombres_columnas(df, **kwargs):\n",
    "    \"\"\"\n",
    "    Cambia los nombres de las columnas de un DataFrame.\n",
    "\n",
    "    Parámetros de entrada:\n",
    "        - df: DataFrame. El dataframe en el que se cambiarán los nombres de las columnas.\n",
    "        - **kwargs: Diccionario de argumentos clave-valor donde la clave representa el nombre actual de la columna\n",
    "                    y el valor representa el nuevo nombre de la columna.\n",
    "\n",
    "    Retorna:\n",
    "        DataFrame. El dataframe con los nombres de las columnas modificados.\n",
    "\n",
    "    Ejemplo:\n",
    "        df = cambiar_nombres_columnas(df, columna1='nueva_columna1', columna2='nueva_columna2')\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \n",
    "        for columna_actual in kwargs.keys():\n",
    "            if columna_actual not in df.columns:\n",
    "                raise ValueError(f\"La columna '{columna_actual}' no existe en el DataFrame.\")\n",
    "\n",
    "        \n",
    "        df = df.rename(columns=kwargs)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cambiar los nombres de las columnas: {e}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"15\"></a> <br>\n",
    "##### create_dataframe_yahoo_finance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea un DataFrame a partir de los datos descargados de Yahoo Finance para un símbolo específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe_yahoo_finance(symbol):\n",
    "    \"\"\"\n",
    "    Crea un DataFrame a partir de los datos descargados de Yahoo Finance para un símbolo específico.\n",
    "\n",
    "    Parámetros de entrada:\n",
    "        - symbol: str. El símbolo del activo financiero para el cual se desea obtener los datos.\n",
    "\n",
    "    Retorna:\n",
    "        DataFrame. El dataframe con los datos descargados de Yahoo Finance.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = yf.download(symbol)\n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error al descargar los datos de Yahoo Finance para el símbolo {symbol}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"16\"></a> <br>\n",
    "##### limpiar_columnas_numericas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpia una columna de un DataFrame, reemplazando los caracteres especiales inválidos por un valor de reemplazo dado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_columnas_numericas(dataframe, columna, caracteres_especiales, valor_reemplazo):\n",
    "    \"\"\"\n",
    "    Limpia una columna de un DataFrame, reemplazando los caracteres especiales inválidos\n",
    "    por un valor de reemplazo dado.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pandas.DataFrame): El DataFrame que contiene la columna a limpiar.\n",
    "        columna (str): El nombre de la columna a limpiar.\n",
    "        caracteres_especiales (list): Lista de caracteres especiales inválidos.\n",
    "        valor_reemplazo (str): Valor utilizado para reemplazar los caracteres especiales.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: El DataFrame con la columna limpia.\n",
    "\n",
    "    Raises:\n",
    "        Exception: Si se encuentra un caracter especial inválido en la columna.\n",
    "    \"\"\"\n",
    "   \n",
    "    columna_datos = dataframe[columna]\n",
    "    \n",
    "    for i, dato in enumerate(columna_datos):\n",
    "        try:\n",
    "            for caracter in caracteres_especiales:\n",
    "                if caracter in dato:\n",
    "                    raise Exception(\"Se encontró un caracter especial inválido en la columna.\")\n",
    "            \n",
    "            for caracter in caracteres_especiales:\n",
    "                dato = dato.replace(caracter, valor_reemplazo)\n",
    "            \n",
    "            columna_datos[i] = dato\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "    \n",
    "    dataframe[columna] = columna_datos\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"17\"></a> <br>\n",
    "##### encoding_proporcional_target_binaria"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función realiza un encoding de una columna de tipo object en un DataFrame de pandas, creando una nueva columna.   \n",
    "Esta función está diseñada para el contexto en el que la variable a predecir sea binaria. El encoding se realiza proporcionalmente al peso que cada variable categórica tiene en el problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_proporcional_target_binaria(dataframe: pd.DataFrame, target: str, columna_categorica: str, nueva_columna: str):\n",
    "    '''\n",
    "    Esta función realiza un encoding de una columna de tipo object en un DataFrame de pandas, creando una nueva columna. Esta función está diseñada para el contexto en el que la variable a predecir sea binaria.\n",
    "\n",
    "    El encoding se realiza proporcionalmente al peso que cada variable categórica tiene en el problema.\n",
    "\n",
    "    Argumentos:\n",
    "    - dataframe: DataFrame de pandas que contiene los datos.\n",
    "    - target: Nombre de la columna a predecir en el DataFrame. Debe ser binaria y se debe indicar como una cadena de texto.\n",
    "    - columna_categorica: Nombre de la columna categórica que se desea encodear. Se debe indicar como una cadena de texto.\n",
    "    - nueva_columna: Nombre de la nueva columna que contendrá los valores encodeados. Se debe indicar como una cadena de texto.\n",
    "    '''\n",
    "\n",
    "\n",
    "    if target not in dataframe.columns:\n",
    "        print(\"La columna target no existe en el DataFrame.\")\n",
    "        return None\n",
    "\n",
    "    if columna_categorica not in dataframe.columns:\n",
    "        print(\"La columna columna_categorica no existe en el DataFrame.\")\n",
    "        return None\n",
    "\n",
    "    if dataframe[target].nunique() != 2:\n",
    "        print(\"La columna target no es binaria.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        dict_proporcional = dict(dataframe.groupby(columna_categorica)[target].mean())\n",
    "        dataframe[nueva_columna] = dataframe[columna_categorica].map(dict_proporcional)\n",
    "        return dataframe\n",
    "    except (KeyError, TypeError) as e:\n",
    "        print(\"Ocurrió un error al codificar la columna categórica:\", str(e))\n",
    "        return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"18\"></a> <br>\n",
    "##### eliminacion_outliers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta funcion eliminamos las filas del dataframe que contiene valores fuera de lo normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminacion_outliers(dataframe: pd.DataFrame, nombre_columna: str):\n",
    "    '''\n",
    "    Esta función elimina las filas del DataFrame que contienen valores atípicos (outliers) en una columna especificada.\n",
    "\n",
    "    Args:\n",
    "    - dataframe: DataFrame de Pandas que contiene los datos.\n",
    "    - nombre_columna: Nombre de la columna en la cual se desean eliminar las filas con outliers. Se deberá indicar en formato string.\n",
    "\n",
    "    Return:\n",
    "    - Devuelve el DataFrame sin los valores atípicos de la columna especificada.\n",
    "    '''\n",
    "\n",
    "    if not isinstance(nombre_columna, str):\n",
    "        raise TypeError(\"El nombre de la columna debe ser un string.\")\n",
    "\n",
    "    if nombre_columna not in dataframe.columns:\n",
    "        raise KeyError(\"La columna especificada no existe en el DataFrame.\")\n",
    "\n",
    "    df = dataframe.copy()\n",
    "    q1 = np.percentile(df[nombre_columna], 25)\n",
    "    q3 = np.percentile(df[nombre_columna], 75)\n",
    "    rango_intercuartilico = q3 - q1\n",
    "    df = df[(df[nombre_columna] >= (q1 - 1.5 * rango_intercuartilico)) & (df[nombre_columna] <= (q3 + 1.5 * rango_intercuartilico))]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"19\"></a> <br>\n",
    "##### comprobacion_outliers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función calcula el número de outliers y su proporción con respecto al total en una columna numérica de un DataFrame de Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprobacion_outliers(dataframe: pd.DataFrame, nombre_columna: str) -> dict:\n",
    "    '''\n",
    "    Esta función calcula el número de outliers y su proporción con respecto al total en una columna numérica de un DataFrame de Pandas.\n",
    "\n",
    "    Args:\n",
    "    - dataframe: DataFrame de Pandas que contiene los datos.\n",
    "    - nombre_columna: Nombre de la columna para la cual se desea detectar los outliers. Se deberá indicar en formato string.\n",
    "\n",
    "    Return:\n",
    "    - Diccionario con el número de outliers en la columna especificada y el porcentaje de outliers en relación al total de datos.\n",
    "    '''\n",
    "    try:\n",
    "        if not isinstance(nombre_columna, str):\n",
    "            raise TypeError(\"El nombre de la columna debe ser un string.\")\n",
    "            \n",
    "        df = dataframe[nombre_columna]\n",
    "        q1 = np.percentile(df, 25)\n",
    "        q3 = np.percentile(df, 75)\n",
    "        rango_intercuartilico = q3 - q1 \n",
    "        outliers = df[(df < (q1 - 1.5 * rango_intercuartilico)) | (df > (q3 + 1.5 * rango_intercuartilico))]\n",
    "        num_outliers = len(outliers)\n",
    "        porcentaje_outliers = round((num_outliers / len(df)) * 100, 2)\n",
    "        \n",
    "        result = {\n",
    "            \"numero_outliers\": num_outliers,\n",
    "            \"porcentaje_outliers\": porcentaje_outliers\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "\n",
    "    except KeyError:\n",
    "        raise KeyError(\"Error: La columna especificada no existe en el DataFrame.\")\n",
    "    except TypeError as e:\n",
    "        raise TypeError(\"Error: \" + str(e))\n",
    "    except Exception as e:\n",
    "        raise Exception(\"Error: Se produjo un problema al procesar la función. Por favor, revisa la documentación de la función, verifica que los parámetros de entrada estén correctamente indicados y revisa los datos de tu DataFrame.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"150\"></a> <br>\n",
    "### *Funciones de modelado*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el ámbito del análisis de datos y el aprendizaje automático, las funciones de modelado desempeñan un papel esencial para comprender los datos y hacer predicciones significativas. El modelado se refiere a la construcción y aplicación de modelos estadísticos o algoritmos de aprendizaje automático que capturan las relaciones y patrones inherentes en los datos.  \n",
    "A continuación se mostrarán todas las funciones de modelado de la biblioteca."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"20\"></a> <br>\n",
    "##### evaluacion_clas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para evaluar las predicciones de un modelo de clasificación de machine learning, devolviendo diferentes métricas en un dataframe.  \n",
    "\n",
    "En caso de tratarse de una clasificación multiclase, el average de las métricas será None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluacion_clas(nom_modelo: str, modelo: Any, X_train: numpy.ndarray, y_train: numpy.ndarray, X_test: numpy.ndarray, y_test: numpy.ndarray, redondeo: int = None) -> pandas.DataFrame: # type: ignore\n",
    "    \"\"\"\n",
    "    Función para evaluar las predicciones de un modelo de clasificación de machine learning, devolviendo diferentes métricas en un dataframe.\n",
    "    En caso de tratarse de una clasificación multiclase, el average de las métricas será None.\n",
    "    Args:\n",
    "        nom_modelo (str): El nombre del modelo.\n",
    "        modelo (Any): Modelo de machine learning para hacer las predicciones.\n",
    "        X_train (numpy.ndarray): Variables predictivas de entrenamiento.\n",
    "        y_train (numpy.ndarray): Target de entrenamiento.\n",
    "        X_test (numpy.ndarray): Variables predictivas de evaluación.\n",
    "        y_test (numpy.ndarray): Target de evaluación.\n",
    "        redondeo (int): Cantidad de decimales para redondear las métricas. (default: None)\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Dataframe con todas las métricas de evaluación del modelo.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        modelo.fit(X_train, y_train)\n",
    "        y_pred = modelo.predict(X_test)\n",
    "        y_pred_prob = modelo.predict_proba(X_test)\n",
    "        \n",
    "        if len(numpy.unique(y_test)) > 2:\n",
    "            average = None\n",
    "            multi_class = 'ovr'\n",
    "        else:\n",
    "            average = 'binary'\n",
    "            multi_class = 'raise'\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average=average)\n",
    "        recall = recall_score(y_test, y_pred, average=average)\n",
    "        f1 = f1_score(y_test, y_pred, average=average)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_prob, multi_class=multi_class)\n",
    "        \n",
    "        if redondeo is not None:\n",
    "            accuracy = numpy.round(accuracy, redondeo)\n",
    "            precision = numpy.round(precision, redondeo)\n",
    "            recall = numpy.round(recall, redondeo)\n",
    "            f1 = numpy.round(f1, redondeo)\n",
    "            roc_auc = numpy.round(roc_auc, redondeo)\n",
    "        \n",
    "        result_df = pandas.DataFrame(data=[[nom_modelo, accuracy, precision, recall, f1, roc_auc]], \n",
    "                                columns=[\"Model\", 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC'])\n",
    "        return result_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"Error al evaluar el modelo'{}':\".format(nom_modelo))\n",
    "        return None # type: ignore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"21\"></a> <br>\n",
    "##### modelo_kmeans_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para hacer un modelo de Clustering para machine learning, devolviendo diferentes métricas en un dataframe.  \n",
    "K-means es un algoritmo de clustering ampliamente utilizado en el campo del aprendizaje automático no supervisado. Su objetivo principal es agrupar un conjunto de datos en k grupos o clústeres basados en sus similitudes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelo_kmeans_df(data: pd.DataFrame, n:int):\n",
    "\n",
    "    \"\"\"\n",
    "    Función para hacer un modelo de Clustering para machine learning, devolviendo diferentes métricas en un dataframe.\n",
    "    Utiliza las columnas numericas del dataframe que se declare en los argumentos.\n",
    "    Además del return genera una gáfica con la media de las distancias de k en el eje Y, y el numero de K en el eje X.\n",
    "\n",
    "\n",
    "    Args:\n",
    "        data (str): El data frame que se quiere modelar.\n",
    "        n (int): Número máximo del rango de K que se quieren untilizar\n",
    "\n",
    "    Returns:\n",
    "        Un pandas.DataFrame con todas las métricas (silhouette_score, Average Distance y SSE (Sum of Squared Errors)) de evaluación del modelo.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        rango = range(2, n)\n",
    "        X = data.select_dtypes(include=np.number)\n",
    "\n",
    "        k_values = []\n",
    "        average_distances = []\n",
    "        sse_values = []\n",
    "        silhouette_scores = []\n",
    "\n",
    "        for k in rango:\n",
    "            modelo = KMeans(n_clusters=k, random_state=42)\n",
    "            modelo.fit(X)\n",
    "\n",
    "            distances = np.min(modelo.transform(X), axis=1)\n",
    "            average_distance = np.mean(distances)\n",
    "            average_distances.append(average_distance)\n",
    "\n",
    "            sse = modelo.inertia_\n",
    "            sse_values.append(sse)\n",
    "\n",
    "            labels = modelo.labels_\n",
    "            silhouette = silhouette_score(X, labels)\n",
    "            silhouette_scores.append(silhouette)\n",
    "\n",
    "            k_values.append(k)\n",
    "\n",
    "        # Crear el DataFrame con las métricas\n",
    "        df_metrics = pd.DataFrame({\n",
    "            'K': k_values,\n",
    "            'Average Distance': average_distances,\n",
    "            'SSE': sse_values,\n",
    "            'Silhouette Score': silhouette_scores\n",
    "        })\n",
    "\n",
    "        # Graficar la distancia media en función de K\n",
    "        plt.plot(rango, average_distances, 'bo-')\n",
    "        plt.xlabel('K')\n",
    "        plt.ylabel('Average Distance')\n",
    "        plt.title('K-Means Average Distance')\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = \"Fallo: \" + str(e)\n",
    "        print(error_message)\n",
    "\n",
    "    return df_metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"22\"></a> <br>\n",
    "##### evaluacion_reg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para evaluar las predicciones de un modelo de regresión de machine learning, devolviendo diferentes métricas en un dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluacion_reg(nom_modelo:str, modelo:Any, X_train:numpy.ndarray, y_train:numpy.ndarray, X_test:numpy.ndarray, y_test:numpy.ndarray) -> pandas.DataFrame:  \n",
    "    '''\n",
    "    Función para evaluar las predicciones de un modelo de regresión de machine learning, devolviendo diferentes métricas en un dataframe.\n",
    "\n",
    "    Args:\n",
    "        nom_modelo (str): El nombre del modelo.\n",
    "        modelo (Any): Modelo de machine learning para hacer las predicciones.\n",
    "        X_train (numpy.ndarray): Variables predictivas de entrenamiento.\n",
    "        y_train (numpy.ndarray): Target de entrenamiento.\n",
    "        X_test (numpy.ndarray): Variables predictivas de evaluación.\n",
    "        y_test (numpy.ndarray): Target de evaluación.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Dataframe con todas las métricas de evaluación del modelo.\n",
    "    '''\n",
    "    try:\n",
    "        modelo.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred= modelo.predict(X_test)\n",
    "        \n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = numpy.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        y_test_mean= y_test.mean()\n",
    "        mae_ratio= mae/y_test_mean\n",
    "        rmse_ratio= rmse/y_test_mean\n",
    "        \n",
    "        result_df = pandas.DataFrame(data=[[nom_modelo, mae, mse, rmse, r2, mae_ratio, rmse_ratio]], \n",
    "                                columns=[\"Model\", 'MAE', 'MSE', 'RMSE', 'R2 Score', \"MAE Ratio\", \"RMSE Ratio\"])\n",
    "        return result_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"Error al evaluar el modelo'{}':\".format(nom_modelo))\n",
    "        return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"23\"></a> <br>\n",
    "##### train_decision_tree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para entrenar un modelo decision tree.  \n",
    "Un árbol de decisión (decision tree) es un modelo de aprendizaje automático que utiliza una estructura de árbol para tomar decisiones o realizar predicciones. Se basa en una serie de preguntas o condiciones lógicas para dividir los datos y llegar a una conclusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_decision_tree(X_train, y_train, max_depth=None, min_samples_split=2):\n",
    "    \"\"\"\n",
    "    Función para entrenar decision tree.\n",
    "    \n",
    "    Args:\n",
    "        X_train (array-like): Matriz de características de entrenamiento.\n",
    "        y_train (array-like): Vector de etiquetas de entrenamiento.\n",
    "        max_depth (int or None, optional): La profundidad máxima del árbol. \n",
    "                                           Si es None, se expande hasta que todas las hojas sean puras o hasta que \n",
    "                                           todas las hojas contengan menos de min_samples_split muestras.\n",
    "        min_samples_split (int, optional): El número mínimo de muestras requeridas para dividir un nodo interno.\n",
    "    \n",
    "    Returns:\n",
    "        model: Modelo decision tree entrenado.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model_dt = DecisionTreeRegressor(max_depth=max_depth, min_samples_split=min_samples_split)\n",
    "        model_dt.fit(X_train, y_train)\n",
    "        \n",
    "        return model_dt\n",
    "    except Exception as e:\n",
    "        print(f\"Error en el entrenamiento: {e}\")\n",
    "        return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"24\"></a> <br>\n",
    "##### train_knn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para entrenar knn.  \n",
    "KNN (K-Nearest Neighbors) es un algoritmo de aprendizaje automático utilizado para problemas de clasificación y regresión. Es un método basado en instancias, lo que significa que no aprende un modelo explícito, sino que realiza predicciones basadas en la proximidad a los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_knn(X_train, y_train, n_neighbors=5, scale_features=True):\n",
    "    \"\"\"\n",
    "    Función para entrenar knn.\n",
    "    \n",
    "    Args:\n",
    "        X_train (array-like): Matriz de características de entrenamiento.\n",
    "        y_train (array-like): Vector de etiquetas de entrenamiento.\n",
    "        n_neighbors (int, optional): El número de vecinos a tener en cuenta durante la clasificación.\n",
    "        scale_features (bool, optional): Indica si se escala la matriz de características. \n",
    "                                         Por defecto, es True.\n",
    "    \n",
    "    Returns:\n",
    "        model_knn: Modelo knn entrenado.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if scale_features:\n",
    "            scaler = StandardScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "        \n",
    "        model_knn = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "        model_knn.fit(X_train, y_train)\n",
    "        \n",
    "        return model_knn\n",
    "    except Exception as e:\n",
    "        print(f\"Error en el entrenamiento: {e}\")\n",
    "        return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"25\"></a> <br>\n",
    "##### train_linear_regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para hacer un modelo de machine learning de linear regression.  \n",
    "La Linear Regression (regresión lineal) es un modelo estadístico utilizado para analizar la relación entre una variable dependiente continua y una o más variables independientes. Se basa en la suposición de que existe una relación lineal entre las variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_regression(X_train, y_train, fit_intercept=True, scale_features=True):\n",
    "    \"\"\"\n",
    "    Función para entrenar linear regression.\n",
    "    \n",
    "    Args:\n",
    "        X_train (array-like): Matriz de características de entrenamiento.\n",
    "        y_train (array-like): Vector de etiquetas de entrenamiento.\n",
    "        fit_intercept (bool, optional): Indica si se ajusta el término de intercepción. \n",
    "                                        Por defecto, es True.\n",
    "        scale_features (bool, optional): Indica si se escala la matriz de características. \n",
    "                                         Por defecto, es True.\n",
    "    \n",
    "    Returns:\n",
    "        model_lr: Modelo linear regression entrenado.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if scale_features:\n",
    "            scaler = StandardScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "        \n",
    "        model_lr = LinearRegression(fit_intercept=fit_intercept)\n",
    "        model_lr.fit(X_train, y_train)\n",
    "        \n",
    "        return model_lr\n",
    "    except Exception as e:\n",
    "        print(f\"Error en el entrenamiento: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"26\"></a> <br>\n",
    "##### train_random_forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para hacer un modelo de machine learning de random forest.  \n",
    "Random Forest (bosque aleatorio) es un algoritmo de aprendizaje automático que se utiliza tanto para problemas de clasificación como de regresión. Es una técnica que combina múltiples árboles de decisión individuales y los combina para obtener una predicción más precisa y robusta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(X_train, y_train, n_estimators=100):\n",
    "    \"\"\"\n",
    "    Función para entrenar random forest.\n",
    "    \n",
    "    Args:\n",
    "        X_train (array-like): Matriz de características de entrenamiento.\n",
    "        y_train (array-like): Vector de etiquetas de entrenamiento.\n",
    "        n_estimators (int, optional): El número de árboles en el bosque.\n",
    "    \n",
    "    Returns:\n",
    "        model_rf: Modelo random forest entrenado.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model_rf = RandomForestRegressor(n_estimators=n_estimators)\n",
    "        model_rf.fit(X_train, y_train)\n",
    "        \n",
    "        return model_rf\n",
    "    except Exception as e:\n",
    "        print(f\"Error en el entrenamiento: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"27\"></a> <br>\n",
    "##### train_svr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para hacer un modelo de machine learning de SVR.  \n",
    "SVR (Support Vector Regression) es un algoritmo de regresión basado en máquinas de vectores de soporte. A diferencia de los modelos de regresión lineal tradicionales, SVR utiliza vectores de soporte para encontrar una función de regresión no lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svr(X_train, y_train, kernel='rbf', scale_features=True):\n",
    "    \"\"\"\n",
    "    Función para entrenar SVR.\n",
    "    \n",
    "    Args:\n",
    "        X_train (array-like): Matriz de características de entrenamiento.\n",
    "        y_train (array-like): Vector de etiquetas de entrenamiento.\n",
    "        kernel (str, optional): El kernel a utilizar. Puede ser 'linear', 'poly', 'rbf', 'sigmoid' o una función personalizada.\n",
    "        scale_features (bool, optional): Indica si se escala la matriz de características. \n",
    "                                         Por defecto, es True.\n",
    "    \n",
    "    Returns:\n",
    "        model_svr: Modelo SVR entrenado.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if scale_features:\n",
    "            scaler = StandardScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "        \n",
    "        model_svr = SVR(kernel=kernel)\n",
    "        model_svr.fit(X_train, y_train)\n",
    "        \n",
    "        return model_svr\n",
    "    except Exception as e:\n",
    "        print(f\"Error en el entrenamiento: {e}\")\n",
    "        return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"28\"></a> <br>\n",
    "##### train_test_split_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide un DataFrame en conjuntos de entrenamiento y prueba para el aprendizaje automático."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_df(df, target_col, test_percent, random_state):\n",
    "    \"\"\"\n",
    "    Divide un DataFrame en conjuntos de entrenamiento y prueba para el aprendizaje automático.\n",
    "\n",
    "    Parámetros:\n",
    "        df (pandas.DataFrame): El DataFrame de entrada.\n",
    "        target_col (str): El nombre de la columna objetivo en el DataFrame.\n",
    "        test_percent (float): El porcentaje de datos para usar en la prueba (entre 0 y 1).\n",
    "        random_state (int): El estado aleatorio para garantizar la reproducibilidad.\n",
    "\n",
    "    Retorna:\n",
    "        X_train (pandas.DataFrame): Las características del conjunto de entrenamiento.\n",
    "        X_test (pandas.DataFrame): Las características del conjunto de prueba.\n",
    "        y_train (pandas.Series): La variable objetivo del conjunto de entrenamiento.\n",
    "        y_test (pandas.Series): La variable objetivo del conjunto de prueba.\n",
    "\n",
    "    Imprime:\n",
    "        La forma de cada conjunto para confirmar la dimensión.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Separar características (X) y variable objetivo (y)\n",
    "        X = df.drop(target_col, axis=1)\n",
    "        y = df[target_col]\n",
    "\n",
    "        # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_percent, random_state=random_state)\n",
    "\n",
    "        print(\"Forma de X:\", X.shape)\n",
    "        print(\"Forma de y:\", y.shape)\n",
    "\n",
    "        print(\"Forma de X_train:\", X_train.shape)\n",
    "        print(\"Forma de X_test:\", X_test.shape)\n",
    "        print(\"Forma de y_train:\", y_train.shape)\n",
    "        print(\"Forma de y_test:\", y_test.shape)\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error al dividir los datos en conjuntos de entrenamiento y prueba:\", str(e))\n",
    "        return None, None, None, None\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"29\"></a> <br>\n",
    "##### balance_target_column_random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equilibra una columna objetivo especificada en el DataFrame utilizando sobremuestreo y submuestreo aleatorio.\n",
    "Los datos se mezclan antes de devolver el DataFrame equilibrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_target_column_random(df, target_column):\n",
    "    \"\"\"\n",
    "    Equilibra una columna objetivo especificada en el DataFrame utilizando sobremuestreo y submuestreo aleatorio.\n",
    "    Los datos se mezclan antes de devolver el DataFrame equilibrado.\n",
    "\n",
    "    Parámetros:\n",
    "        df (pandas.DataFrame): El DataFrame de entrada que contiene la columna objetivo.\n",
    "        target_column (str): El nombre de la columna objetivo a equilibrar.\n",
    "\n",
    "    Retorna:\n",
    "        pandas.DataFrame: Un nuevo DataFrame con la columna objetivo equilibrada y mezclada.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Separar características (X) y variable objetivo (y)\n",
    "        X = df.drop(target_column, axis=1)\n",
    "        y = df[target_column]\n",
    "\n",
    "        # Instanciar RandomOverSampler y RandomUnderSampler\n",
    "        oversampler = RandomOverSampler(random_state=42)\n",
    "        undersampler = RandomUnderSampler(random_state=42)\n",
    "\n",
    "        # Sobremuestrear la clase mayoritaria\n",
    "        X_oversampled, y_oversampled = oversampler.fit_resample(X, y)\n",
    "\n",
    "        # Submuestrear la clase minoritaria\n",
    "        X_resampled, y_resampled = undersampler.fit_resample(X_oversampled, y_oversampled)\n",
    "\n",
    "        # Crear un nuevo DataFrame equilibrado\n",
    "        balanced_df = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "\n",
    "        # Mezclar los datos\n",
    "        balanced_df = shuffle(balanced_df, random_state=42)\n",
    "\n",
    "        return balanced_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error al equilibrar la columna objetivo:\", str(e))\n",
    "        return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"30\"></a> <br>\n",
    "##### balance_target_column_smote"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equilibra una columna objetivo especificada en el DataFrame utilizando una combinación de sobremuestreo y submuestreo.\n",
    "Los datos se mezclan antes de devolver el DataFrame equilibrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_target_column_smote(df, target_column):\n",
    "    \"\"\"\n",
    "    Equilibra una columna objetivo especificada en el DataFrame utilizando una combinación de sobremuestreo y submuestreo.\n",
    "    Los datos se mezclan antes de devolver el DataFrame equilibrado.\n",
    "\n",
    "    Parámetros:\n",
    "        df (pandas.DataFrame): El DataFrame de entrada que contiene la columna objetivo.\n",
    "        target_column (str): El nombre de la columna objetivo a equilibrar.\n",
    "\n",
    "    Retorna:\n",
    "        pandas.DataFrame: Un nuevo DataFrame con la columna objetivo equilibrada y mezclada.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Separar características (X) y variable objetivo (y)\n",
    "        X = df.drop(target_column, axis=1)\n",
    "        y = df[target_column]\n",
    "\n",
    "        # Instanciar el muestreador SMOTEENN\n",
    "        sampler = SMOTEENN(random_state=42)\n",
    "\n",
    "        # Remuestrear los datos\n",
    "        X_resampled, y_resampled = sampler.fit_resample(X, y)\n",
    "\n",
    "        # Crear un nuevo DataFrame equilibrado\n",
    "        balanced_df = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "\n",
    "        # Mezclar los datos\n",
    "        balanced_df = shuffle(balanced_df, random_state=42)\n",
    "\n",
    "        return balanced_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error al equilibrar la columna objetivo:\", str(e))\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"31\"></a> <br>\n",
    "##### reductor_calidad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para hacer reducir el tamaño de memoria que ocupa una imagen reduciendo el numero de colores de ésta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reductor_calidad(path_imagen:str,n:int):\n",
    "    \n",
    "    \"\"\"\n",
    "    Función para hacer reducir el tamaño de memoria que ocupa una imagen reduciendo el numero de colores de ésta. \n",
    "\n",
    "    Args:\n",
    "        path_imagen (str): El data frame que se quiere modelar.\n",
    "        n (int): Número de colores total del que se desea la foto.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "\n",
    "        imagen = Image.open(path_imagen)\n",
    "        imagen_1 = np.asarray(imagen,dtype=np.float32)/255\n",
    "\n",
    "        w, h = imagen.size\n",
    "        colors = imagen.getcolors(w * h)\n",
    "        num_colores_0 = len(colors) \n",
    "        num_pixels_0 = w*h \n",
    "        \n",
    "        R = imagen_1[:,:,0]\n",
    "        G = imagen_1[:,:,1]\n",
    "        B = imagen_1[:,:,2]\n",
    "        XR = R.reshape((-1, 1))  \n",
    "        XG = G.reshape((-1, 1)) \n",
    "        XB = B.reshape((-1, 1)) \n",
    "        X = np.concatenate((XR,XG,XB),axis=1)\n",
    "        \n",
    "        k_means = KMeans(n_clusters=n)\n",
    "        k_means.fit(X)\n",
    "        centroides = k_means.cluster_centers_\n",
    "        etiquetas = k_means.labels_\n",
    "        m = XR.shape\n",
    "        for i in range(m[0]):\n",
    "            XR[i] = centroides[etiquetas[i]][0] \n",
    "            XG[i] = centroides[etiquetas[i]][1] \n",
    "            XB[i] = centroides[etiquetas[i]][2] \n",
    "        XR.shape = R.shape \n",
    "        XG.shape = G.shape\n",
    "        XB.shape = B.shape \n",
    "        XR = XR[:, :, np.newaxis]  \n",
    "        XG = XG[:, :, np.newaxis]\n",
    "        XB = XB[:, :, np.newaxis]\n",
    "        Y = np.concatenate((XR,XG,XB),axis=2)\n",
    "        \n",
    "        plt.figure(figsize=(12,12))\n",
    "        plt.imshow(Y)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "        print (u'Número de colores iniciales = ', num_colores_0)\n",
    "        print (u'Número de colores finales = ', n)\n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = \"Fallo: \" + str(e)\n",
    "        print(error_message)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"32\"></a> <br>\n",
    "##### ByN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función que devuelve la imagen que se introduce en blanco y negro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ByN(path_imagen:str):\n",
    "\n",
    "    \"\"\"\n",
    "    Función que devuelve la misma imagen que se introduce pero en blanco y negro.\n",
    "\n",
    "    Args:\n",
    "        path_imagen (str): La dirección de la imagen.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "\n",
    "        imagen = Image.open(path_imagen)\n",
    "\n",
    "        \n",
    "        imagen = imagen.convert('L')\n",
    "        imagen_2 = np.asarray(imagen,dtype=np.float)\n",
    "\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.imshow(imagen_2,cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = \"Fallo: \" + str(e)\n",
    "        print(error_message)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"33\"></a> <br>\n",
    "##### comparar_modelos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para comparar las métricas de varios modelos y devolver el modelo con mejores metricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparar_modelos(modelos, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Funcion para comparar las metricas de varios modelos y devolver el modelo con mejores metricas.\n",
    "\n",
    "    Parametros\n",
    "    ----------\n",
    "        modelos: lista con los modelos a comparar.\n",
    "\n",
    "        X_test: variables a predecir.\n",
    "\n",
    "        y_test: predicción.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        Mejor modelo: el modelo con mejores métricas.\n",
    "    \"\"\"\n",
    "    mejor_modelo = None\n",
    "    mejor_r2 = -np.inf  #marcamos peor metrica posible\n",
    "    mejor_mae = np.inf\n",
    "    mejor_mape = np.inf\n",
    "    mejor_mse = np.inf\n",
    "    \n",
    "\n",
    "        \n",
    "    for modelo in modelos:\n",
    "        try:\n",
    "            y_pred = modelo.predict(X_test)\n",
    "\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "            if r2 > mejor_r2:\n",
    "                mejor_modelo = modelo\n",
    "                mejor_r2 = r2\n",
    "                mejor_mae = mae\n",
    "                mejor_mape = mape\n",
    "                mejor_mse = mse\n",
    "        except Exception as e:\n",
    "            print(f\"Error al evaluar el modelo {modelo}: {str(e)}\")\n",
    "    \n",
    "        print(\"Mejor modelo:\", str(mejor_modelo))\n",
    "        print(\"Mejor R2 Score:\", mejor_r2)\n",
    "        print(\"Mejor MAE:\", mejor_mae)\n",
    "        print(\"Mejor MAPE:\", mejor_mape)\n",
    "        print(\"Mejor MSE:\", mejor_mse)\n",
    "        \n",
    "        return mejor_modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"34\"></a> <br>\n",
    "##### export_import_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para exportar o importar el modelo entrenado concreto que se utilizó anteriormente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_import_model(model, path_model, name, save=True, open=False):\n",
    "    '''\n",
    "    Funcion para exportar o importar el modelo entrenado\n",
    "    Parametros\n",
    "    ----------\n",
    "        model: el modelo a guardar.\n",
    "        path_model: directorio donde se almacenará.\n",
    "        name: nombre del modelo a guardar.\n",
    "        \n",
    "        save: por defecto nos guarda el modelo entrenado.\n",
    "        open: por defecto False. Si True, importamos el modelo entrenado\n",
    "    '''\n",
    "\n",
    "    # Exportamos el modelo con el nombre seleccionado, al path escogido.\n",
    "    filename = os.path.join(path_model, name)\n",
    "\n",
    "    if save:\n",
    "        try:\n",
    "            with open(filename, 'wb') as archivo_salida:\n",
    "                pickle.dump(model, archivo_salida)\n",
    "        except Exception as e:\n",
    "            print(f\"Error al guardar el modelo: {str(e)}\")\n",
    "\n",
    "    if open:\n",
    "        try:\n",
    "            with open(filename, 'rb') as archivo_entrada:\n",
    "                model_pretrained = pickle.load(archivo_entrada)\n",
    "        except Exception as e:\n",
    "            print(f\"Error al cargar el modelo: {str(e)}\")\n",
    "            model_pretrained = None\n",
    "\n",
    "    return model_pretrained"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"35\"></a> <br>\n",
    "##### comparar_scaled"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para comparar las métricas de un modelo, escalando o no los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparar_scaled(modelo, x_train, x_test, y_train, y_test):\n",
    "    '''\n",
    "    Funcion para comparar las metricas de un modelo, escalando o no los datos.\n",
    "\n",
    "    Parametros\n",
    "    ----------\n",
    "        modelo (objeto): El modelo de machine learning que se utilizará para las predicciones.\n",
    "\n",
    "        x_train (array-like): Los datos de entrenamiento sin escalar.\n",
    "\n",
    "        x_test (array-like): Los datos de prueba sin escalar.\n",
    "\n",
    "        y_train (array-like): Las etiquetas de entrenamiento correspondientes a x_train.\n",
    "        \n",
    "        y_test (array-like): Las etiquetas de prueba correspondientes a x_test.\n",
    "    '''\n",
    "    # Entrenar el modelo con x_train sin escalar\n",
    "    model1 = modelo\n",
    "    try:\n",
    "        model1.fit(x_train, y_train)\n",
    "    except Exception as e:\n",
    "        warnings.warn(f\"Error al entrenar el modelo sin escalar: {str(e)}\")\n",
    "\n",
    "    # Obtener las predicciones del modelo en x_test sin escalar\n",
    "    try:\n",
    "        y_pred = model1.predict(x_test)\n",
    "    except Exception as e:\n",
    "        warnings.warn(f\"Error al hacer predicciones sin escalar: {str(e)}\")\n",
    "        \n",
    "\n",
    "    # Calcular las métricas de evaluación utilizando y_test y las predicciones correspondientes\n",
    "    try:\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "    except Exception as e:\n",
    "        warnings.warn(f\"Error al calcular las métricas sin escalar: {str(e)}\")\n",
    "        r2, mae, mape, mse = None, None, None, None\n",
    "\n",
    "    # Imprimir los resultados para x_train sin escalar\n",
    "    print(\"Modelo: x_train\")\n",
    "    print(\"R2 Score:\", r2)\n",
    "    print(\"MAE:\", mae)\n",
    "    print(\"MAPE:\", mape)\n",
    "    print(\"MSE:\", mse)\n",
    "    print()\n",
    "\n",
    "    # Crear el objeto StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Ajustar el scaler utilizando x_train\n",
    "    try:\n",
    "        scaler.fit(x_train)\n",
    "    except Exception as e:\n",
    "        warnings.warn(f\"Error al ajustar el scaler: {str(e)}\")\n",
    "\n",
    "    # Escalar x_train y x_test\n",
    "    try:\n",
    "        x_train_scaled = scaler.transform(x_train)\n",
    "        x_test_scaled = scaler.transform(x_test)\n",
    "    except Exception as e:\n",
    "        warnings.warn(f\"Error al escalar los datos: {str(e)}\")\n",
    "        x_train_scaled, x_test_scaled = None, None\n",
    "\n",
    "    # Entrenar el modelo con x_train_scaled\n",
    "    model_scal = modelo\n",
    "    try:\n",
    "        model_scal.fit(x_train_scaled, y_train)\n",
    "    except Exception as e:\n",
    "        warnings.warn(f\"Error al entrenar el modelo escalado: {str(e)}\")\n",
    "\n",
    "    # Obtener las predicciones del modelo en x_test_scaled\n",
    "    try:\n",
    "        y_pred_scaled = model_scal.predict(x_test_scaled)\n",
    "    except Exception as e:\n",
    "        warnings.warn(f\"Error al hacer predicciones escaladas: {str(e)}\")\n",
    "        \n",
    "    # Calcular las métricas de evaluación utilizando y_test y las predicciones correspondientes\n",
    "    try:\n",
    "        r2_scaled = r2_score(y_test, y_pred_scaled)\n",
    "        mae_scaled = mean_absolute_error(y_test, y_pred_scaled)\n",
    "        mape_scaled = mean_absolute_percentage_error(y_test, y_pred_scaled)\n",
    "        mse_scaled = mean_squared_error(y_test, y_pred_scaled)\n",
    "    except Exception as e:\n",
    "        warnings.warn(f\"Error al calcular las métricas sin escalar: {str(e)}\")\n",
    "        r2_scaled, mae_scaled, mape_scaled, mse_scaled = None, None, None, None\n",
    "    \n",
    "\n",
    "    # Imprimir los resultados para x_train_scaled\n",
    "    print(\"Modelo: x_train_scaled\")\n",
    "    print(\"R2 Score:\", r2_scaled)\n",
    "    print(\"MAE:\", mae_scaled)\n",
    "    print(\"MAPE:\", mape_scaled)\n",
    "    print(\"MSE:\", mse_scaled)\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"200\"></a> <br>\n",
    "### *Funciones de visualización*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el análisis de datos y la ciencia de datos, las funciones de visualización juegan un papel fundamental en la exploración y comunicación de los datos. Estas funciones se centran en la representación gráfica de los datos y en la creación de visualizaciones efectivas y comprensibles.  \n",
    "A continuación se mostrarán todas las funciones de visualización de la biblioteca.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"36\"></a> <br>\n",
    "##### plot_moving_averages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genera un gráfico interactivo utilizando la biblioteca Plotly que muestra las medias móviles de una característica específica en un conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_moving_averages (data:pd.DataFrame, feature:str, medias_moviles=None, colores=None):\n",
    "    '''\n",
    "    Genera un gráfico interactivo utilizando la biblioteca Plotly que muestra las medias móviles de una característica específica en un conjunto de datos.\n",
    "\n",
    "    Parámetros:\n",
    "    - data (pd.DataFrame): El conjunto de datos que contiene la información.\n",
    "    - feature (str): El nombre de la característica para la cual se calcularán las medias móviles y se mostrarán en el gráfico.\n",
    "    - medias_moviles (list, opcional): Una lista de enteros que representan las ventanas de las medias móviles. Por defecto, se utilizan [8, 21, 30, 50, 100, 200].\n",
    "    - colores (list, opcional): Una lista de colores en formato de cadena para asignar a las medias móviles. Debe tener la misma longitud que la lista de medias móviles. Por defecto, se utilizan ['orange', 'blue', 'grey', 'green', 'purple', 'red'].\n",
    "\n",
    "    Retorna:\n",
    "    - data (pd.DataFrame): El conjunto de datos original con las columnas de medias móviles agregadas.\n",
    "    - fig (plotly.graph_objects.Figure): El gráfico interactivo generado con Plotly.\n",
    "\n",
    "    Ejemplo de uso:\n",
    "    data = pd.read_csv('datos.csv')\n",
    "    plot_moving_averages(data, 'Precio', medias_moviles=[10, 20, 30], colores=['red', 'blue', 'green'])\n",
    "    '''\n",
    "    try:\n",
    "        # Definir las medias móviles\n",
    "        if medias_moviles is None:\n",
    "            medias_moviles = [8, 21, 30, 50, 100, 200]\n",
    "            \n",
    "        # Definir los colores para las medias móviles\n",
    "        if colores is None:\n",
    "            colores = ['orange', 'blue', 'grey', 'green', 'purple', 'red']\n",
    "\n",
    "        # Calcular las medias móviles\n",
    "        for ma in medias_moviles:\n",
    "            columna = 'MA_' + str(ma)  # Nombre de la columna de la media móvil\n",
    "            data[columna] = data[feature].rolling(window=ma).mean()\n",
    "\n",
    "        # Crear la figura de Plotly\n",
    "        fig = go.Figure()\n",
    "\n",
    "        # Agregar 'feature' al gráfico\n",
    "        fig.add_trace(go.Scatter(x=data.index, y=data[feature], name='Precio', line=dict(color='blue', width=1)))\n",
    "\n",
    "        # Agregar las medias móviles al gráfico con colores diferentes\n",
    "        for ma, color in zip(medias_moviles, colores):\n",
    "            columna = 'MA_' + str(ma)\n",
    "            fig.add_trace(go.Scatter(x=data.index, y=data[columna], name='MA ' + str(ma), line=dict(color=color, width=0.5)))\n",
    "\n",
    "        # Personalizar el diseño del gráfico\n",
    "        fig.update_layout(\n",
    "            title={'text': 'Medias Móviles', 'x': 0.5, 'xanchor': 'center'},\n",
    "            xaxis_title='Fecha',\n",
    "            yaxis_title=feature,\n",
    "        )\n",
    "\n",
    "        # Mostrar el gráfico interactivo\n",
    "        fig.show()\n",
    "\n",
    "        return data, fig\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"Error en la función plot_moving_averages:\", str(e))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"37\"></a> <br>\n",
    "##### plot_pca_importance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genera un gráfico de barras que muestra el porcentaje de varianza explicada por cada componente principal en un modelo de PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca_importance (data, modelo_pca):\n",
    "    '''\n",
    "    Genera un gráfico de barras que muestra el porcentaje de varianza explicada por cada componente principal\n",
    "    en un modelo de PCA.\n",
    "\n",
    "    Parámetros:\n",
    "    - data: El conjunto de datos utilizado en el modelo de PCA.\n",
    "    - modelo_pca: El objeto del modelo de PCA entrenado.\n",
    "\n",
    "    Retorna:\n",
    "    - fig: El objeto Figure del gráfico generado.\n",
    "\n",
    "    '''\n",
    "    try:\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "        ax.bar(\n",
    "            x      = np.arange(modelo_pca.n_components_) + 1,\n",
    "            height = modelo_pca.explained_variance_ratio_\n",
    "        )\n",
    "\n",
    "        for x, y in zip(np.arange(len(data.columns)) + 1, modelo_pca.explained_variance_ratio_):\n",
    "            label = round(y, 2)\n",
    "            ax.annotate(\n",
    "                label,\n",
    "                (x,y),\n",
    "                textcoords=\"offset points\",\n",
    "                xytext=(0,10),\n",
    "                ha='center'\n",
    "            )\n",
    "\n",
    "        ax.set_xticks(np.arange(modelo_pca.n_components_) + 1)\n",
    "        ax.set_ylim(0, 1.1)\n",
    "        ax.set_title('Porcentaje de varianza explicada por cada componente')\n",
    "        ax.set_xlabel('Componente principal')\n",
    "        ax.set_ylabel('Por. varianza explicada')\n",
    "\n",
    "        fig.show()\n",
    "\n",
    "        return fig\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"Ocurrió un error en plot_pca_importance:\", str(e))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"38\"></a> <br>\n",
    "##### plot_pca_importance_agg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genera un gráfico de línea que muestra el porcentaje acumulado de varianza explicada por cada componente principal en un modelo de PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca_importance_agg (data, modelo_pca):\n",
    "    '''\n",
    "    Genera un gráfico de línea que muestra el porcentaje acumulado de varianza explicada por cada componente principal\n",
    "    en un modelo de PCA.\n",
    "\n",
    "    Parámetros:\n",
    "    - data: El conjunto de datos utilizado en el modelo de PCA.\n",
    "    - modelo_pca: El objeto del modelo de PCA entrenado.\n",
    "\n",
    "    Retorna:\n",
    "    - fig: El objeto Figure del gráfico generado.\n",
    "\n",
    "    '''\n",
    "    try:\n",
    "        prop_varianza_acum = modelo_pca.explained_variance_ratio_.cumsum()\n",
    "\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "        ax.plot(\n",
    "            np.arange(len(data.columns)) + 1,\n",
    "            prop_varianza_acum,\n",
    "            marker = 'o'\n",
    "        )\n",
    "\n",
    "        for x, y in zip(np.arange(len(data.columns)) + 1, prop_varianza_acum):\n",
    "            label = round(y, 2)\n",
    "            ax.annotate(\n",
    "                label,\n",
    "                (x,y),\n",
    "                textcoords=\"offset points\",\n",
    "                xytext=(0,10),\n",
    "                ha='center'\n",
    "            )\n",
    "            \n",
    "        ax.set_ylim(0, 1.1)\n",
    "        ax.set_xticks(np.arange(modelo_pca.n_components_) + 1)\n",
    "        ax.set_title('Porcentaje de varianza explicada acumulada')\n",
    "        ax.set_xlabel('Componente principal')\n",
    "        ax.set_ylabel('% varianza acumulada')\n",
    "\n",
    "        fig.show()\n",
    "\n",
    "        return fig\n",
    "    \n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Ocurrió un error en plot_pca_importance_agg:\", str(e))\n",
    "        \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"39\"></a> <br>\n",
    "##### plot_scatter_with_reference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genera un gráfico de dispersión con una línea de referencia para comparar los valores de prueba con los valores predichos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_with_reference(y_test: np.array, predictions: np.array, title: str) -> None:\n",
    "    \"\"\"\n",
    "    Genera un gráfico de dispersión con una línea de referencia para comparar los valores de prueba con los valores predichos.\n",
    "\n",
    "    Args:\n",
    "        y_test (array-like): Valores de prueba.\n",
    "        predictions (array-like): Valores predichos.\n",
    "        title (str): Título del gráfico.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        sns.set(style=\"darkgrid\")\n",
    "        plt.scatter(y_test, predictions, color='blue',\n",
    "                    label='Valores de prueba vs. Valores predichos')\n",
    "        # Línea de referencia: valores reales = valores predichos\n",
    "        plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--')\n",
    "        plt.scatter(y_test, y_test, color='red', label='Valores de prueba')\n",
    "        plt.xlabel('Valores de prueba')\n",
    "        plt.ylabel('Valores predichos')\n",
    "        plt.title(title)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(\"Ocurrió un error al generar el gráfico de dispersión:\", str(e))\n",
    "    finally:\n",
    "        return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"40\"></a> <br>\n",
    "##### plot_learning_curve"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genera una curva de aprendizaje para un estimador dado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, X, y, cv=None, train_sizes=np.linspace(0.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Genera una curva de aprendizaje para un estimador dado.\n",
    "\n",
    "    Parámetros:\n",
    "    estimator: objeto de estimador\n",
    "    X: matriz de características\n",
    "    y: vector de etiquetas\n",
    "    cv: validación cruzada (opcional)\n",
    "    train_sizes: tamaños de los conjuntos de entrenamiento (opcional)\n",
    "\n",
    "    Devuelve:\n",
    "    None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        plt.figure()\n",
    "        plt.title(\"Curva de aprendizaje\")\n",
    "        plt.xlabel(\"Tamaño del conjunto de entrenamiento\")\n",
    "        plt.ylabel(\"Score\")\n",
    "\n",
    "        train_sizes, train_scores, test_scores = learning_curve(\n",
    "            estimator, X, y, cv=cv, train_sizes=train_sizes)\n",
    "\n",
    "        # Calcular la media y el desvío estándar del training score\n",
    "        train_scores_mean = np.mean(train_scores, axis=1)\n",
    "        train_scores_std = np.std(train_scores, axis=1)\n",
    "\n",
    "        # Graficar la curva de aprendizaje del training score\n",
    "        plt.grid()\n",
    "        plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                         color=\"r\")\n",
    "        plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                 label=\"Training score\")\n",
    "\n",
    "        plt.legend(loc=\"best\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"41\"></a> <br>\n",
    "##### plot_precision_recall_curve"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genera una curva de precisión-recall que es una representación gráfica que muestra la relación entre la tasa de verdaderos positivos (TPR) y el porcentaje de ejemplos positivos recuperados (recall) a medida que se varía el umbral de clasificación en un modelo de clasificación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_curve(y_true, y_prob):\n",
    "    \"\"\"\n",
    "    Genera una curva de precisión-recall dadas las etiquetas verdaderas y las probabilidades predichas.\n",
    "\n",
    "    Parámetros:\n",
    "    y_true: vector de etiquetas verdaderas\n",
    "    y_prob: vector de probabilidades predichas\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Verificar si los argumentos son válidos\n",
    "        y_true = column_or_1d(y_true)\n",
    "        y_prob = column_or_1d(y_prob)\n",
    "        check_consistent_length(y_true, y_prob)\n",
    "\n",
    "        # Calcular la precisión y el recall para diferentes umbrales\n",
    "        precision, recall, _ = precision_recall_curve(y_true, y_prob)\n",
    "\n",
    "        # Generar la gráfica\n",
    "        plt.plot(recall, precision)\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision-Recall Curve')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        raise e"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"42\"></a> <br>\n",
    "##### plot_roc_curve"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para visualizar la roc-curve, esta curva muestra la relación entre la tasa de verdaderos positivos (TPR) y la tasa de falsos positivos (FPR) a medida que se varía el umbral de clasificación del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_true, y_score):\n",
    "    try:\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "        plt.plot(fpr, tpr)\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curve')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"43\"></a> <br>\n",
    "##### dist_variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para visualizar las distribuciones de las variables en un DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_variables(data: pd.DataFrame, target: str = None, ncols: int = 2, figsize: tuple = (30, 30)) -> plt.Figure: # type: ignore\n",
    "    \"\"\"\n",
    "    Función para visualizar las distribuciones de las variables en un DataFrame.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): DataFrame con los datos.\n",
    "        target (str or None): Nombre de la columna objetivo. Si es None, no se divide por grupos (default: None).\n",
    "        ncols (int): Número de columnas en la figura de subplots (default: 2).\n",
    "        figsize (tuple): Tamaño de la figura (default: (15, 20)).\n",
    "\n",
    "    Returns:\n",
    "        plt.Figure: Figura con todas las distribuciones de los datos.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        total_columns = len(data.columns)\n",
    "        nrows = int(np.ceil(total_columns / ncols))\n",
    "\n",
    "        fig, axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        axes = axes.ravel() # type: ignore\n",
    "\n",
    "        for i, column in enumerate(data.columns):\n",
    "            ax = axes[i]\n",
    "\n",
    "            if target is not None:\n",
    "                # Variables categóricas\n",
    "                if data[column].dtype == 'object':\n",
    "                    sns.countplot(x=column, hue=target, data=data, ax=ax)\n",
    "                    ax.set_title(column)\n",
    "                    ax.legend(title=target)\n",
    "                # Variables continuas\n",
    "                else:\n",
    "                    for value in data[target].unique():\n",
    "                        sns.histplot(data[data[target] == value][column], ax=ax, label=value)\n",
    "                    ax.set_title(column)\n",
    "                    ax.legend(title=target)\n",
    "            else:\n",
    "                # Variables categóricas\n",
    "                if data[column].dtype == 'object':\n",
    "                    sns.countplot(x=column, data=data, ax=ax)\n",
    "                    ax.set_title(column)\n",
    "                # Variables continuas\n",
    "                else:\n",
    "                    sns.histplot(data[column], ax=ax)\n",
    "                    ax.set_title(column)\n",
    "\n",
    "        return fig\n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = \"Ocurrió un error durante la visualización: \" + str(e)\n",
    "        print(error_message)\n",
    "        return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"44\"></a> <br>\n",
    "##### plot_correlations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función crea un gráfico de barras que muestra las correlaciones de la variable objetivo con el resto de las variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlations(dataframe, target, figsize, filename):\n",
    "    \n",
    "    try:\n",
    "        \"\"\"Esta función crea un gráfico de barras que muestra las correlaciones de la variable objetivo con el resto de las variables.\n",
    "\n",
    "        Args:\n",
    "        dataframe (pd.DataFrame): El DataFrame que contiene los datos.\n",
    "        target (str): El nombre de la columna que representa la variable objetivo.\n",
    "        figsize (tuple): El tamaño de la figura del gráfico en pulgadas (ancho, alto).\n",
    "        filename (str): El nombre del archivo en el que se guardará la figura.\n",
    "        \"\"\"\n",
    "\n",
    "        #para calcular las correlaciones de la variable objetivo con el resto de las variables con dataframe.corr()\n",
    "        correlations = dataframe.corr()[target].drop(target)\n",
    "\n",
    "        #Ordenar las correlaciones de mayor a menor usando correlations.sort_values()\n",
    "        correlations = correlations.sort_values(ascending=False)\n",
    "\n",
    "        #tamaño de la figura\n",
    "        plt.figure(figsize=figsize)\n",
    "\n",
    "        #gráfico de barras con sns.barplot()\n",
    "        sns.barplot(x=correlations, y=correlations.index, palette='Blues')\n",
    "\n",
    "        #Añadir los ejes y el título usando plt.xlabel(), plt.ylabel() y plt.title()\n",
    "        plt.xlabel('Correlación')\n",
    "        plt.ylabel('Variable')\n",
    "        plt.title(f'Correlaciones de {target} con el resto de las variables')\n",
    "\n",
    "        #Guardar la figura en un archivo\n",
    "        plt.savefig(filename)\n",
    "\n",
    "        #gráfico\n",
    "        plt.show()\n",
    "    \n",
    "    except Exception as e:\n",
    "        error_message = \"Ocurrió un error durante la visualización: \" + str(e)\n",
    "        print(error_message)\n",
    "        return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"45\"></a> <br>\n",
    "##### plot_map"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función crea un mapa interactivo a partir de un DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_map(dataframe, figsize):\n",
    "    \n",
    "    try:\n",
    "        \"\"\"Esta función crea un mapa interactivo a partir de un DataFrame.\n",
    "\n",
    "        Argumentos:\n",
    "            dataframe (pd.DataFrame): El DataFrame que contiene los datos.\n",
    "            figsize (tuple): El tamaño de la figura del mapa en píxeles (ancho, alto).\n",
    "        \"\"\"\n",
    "\n",
    "        #Crear el mapa usando folium.Map()\n",
    "        mapa = folium.Map(location=[dataframe['lat'].mean(), dataframe['lon'].mean()], \n",
    "                        zoom_start=10, tiles='Stamen Terrain')\n",
    "\n",
    "        #Añadir marcadores con folium.Marker()\n",
    "        for i, row in dataframe.iterrows():\n",
    "            folium.Marker(location=[row['lat'], row['lon']],\n",
    "                        popup=row['name'], \n",
    "                        icon=folium.Icon(color=row['color'])).add_to(mapa)\n",
    "\n",
    "        #Mostrar el mapa usando folium.Figure()\n",
    "        fig = folium.Figure(width=figsize[0], height=figsize[1])\n",
    "        fig.add_child(mapa)\n",
    "        mapa.save(\"map.html\") #PARA QUE SE VEA EL MAPA\n",
    "        fig\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_message = \"Ocurrió un error durante la visualización: \" + str(e)\n",
    "        print(error_message)\n",
    "        return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"46\"></a> <br>\n",
    "##### plot_wordcloud"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función crea una nube de palabras a partir de un texto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wordcloud(text, figsize, filename):\n",
    "    try:\n",
    "        \"\"\"Esta función crea una nube de palabras a partir de un texto.\n",
    "\n",
    "        Argumentos=\n",
    "            text (str): El texto que contiene las palabras.\n",
    "            figsize (tuple): El tamaño de la figura de la nube de palabras en pulgadas (ancho, alto).\n",
    "            filename (str): El nombre del archivo en el que se guardará la figura.\n",
    "        \"\"\"\n",
    "\n",
    "        #Nube de palabras creada usando WordCloud()\n",
    "        wc = WordCloud(background_color='white', \n",
    "                    max_words=100, \n",
    "                    width=figsize[0]*100, \n",
    "                    height=figsize[1]*100).generate(text)\n",
    "\n",
    "        #Tamaño de la figura\n",
    "        plt.figure(figsize=figsize)\n",
    "\n",
    "        #Mostrar la nube de palabras usando plt.imshow() y plt.axis()\n",
    "        plt.imshow(wc, interpolation='bilinear')\n",
    "        plt.axis('off')\n",
    "\n",
    "        #Guardar\n",
    "        plt.savefig(filename)\n",
    "\n",
    "        #Mostrar\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        error_message = \"Ocurrió un error durante la visualización: \" + str(e)\n",
    "        print(error_message)\n",
    "        return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"47\"></a> <br>\n",
    "##### plot_quality_counts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea un gráfico de barras que muestra el recuento de valores en una columna específica.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_quality_counts(dataframe: pd.DataFrame, column: str, color: str) -> None:\n",
    "    \"\"\"Crea un gráfico de barras que muestra el recuento de valores en una columna específica.\n",
    "    \n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): El DataFrame que contiene los datos.\n",
    "        column (str): El nombre de la columna para la cual se desea hacer el gráfico de barras.\n",
    "        color (str): El color de las barras del gráfico.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Crea el gráfico de barras utilizando value_counts() y plot.bar()\n",
    "        dataframe[column].value_counts().plot.bar(rot=0, color=color)\n",
    "        \n",
    "        # Personaliza el gráfico\n",
    "        plt.ylabel('Recuento')\n",
    "        plt.xlabel(column)\n",
    "        \n",
    "        # Muestra el gráfico\n",
    "        plt.show()\n",
    "    except KeyError:\n",
    "        print(f\"La columna '{column}' no existe en el DataFrame.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ocurrió un error: {str(e)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"48\"></a> <br>\n",
    "##### plot_heatmap"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea un mapa de calor (heatmap) a partir de un DataFrame.   Un heatmap es una representación visual que utiliza colores para mostrar la densidad o la distribución de datos.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(dataframe: pd.DataFrame, figsize: tuple) -> None:\n",
    "    \"\"\"Crea un mapa de calor (heatmap) a partir de un DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): El DataFrame que contiene los datos.\n",
    "        figsize (tuple): El tamaño de la figura del heatmap en pulgadas (ancho, alto).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Configurar el tamaño de la figura\n",
    "        plt.figure(figsize=figsize)\n",
    "        \n",
    "        # Crear el mapa de calor utilizando sns.heatmap()\n",
    "        sns.heatmap(dataframe.corr(), annot=True)\n",
    "        \n",
    "        # Mostrar el mapa de calor\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Ocurrió un error: {str(e)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"49\"></a> <br>\n",
    "##### plot_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea un gráfico de barras que muestra el recuento de valores en una columna específica.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(dataframe: pd.DataFrame, x: str, y: str, plot_type: str) -> None:\n",
    "    \"\"\"Visualiza diferentes tipos de gráficos a partir de un DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): El DataFrame que contiene los datos.\n",
    "        x (str): La columna del DataFrame para el eje x.\n",
    "        y (str): La columna del DataFrame para el eje y.\n",
    "        plot_type (str): El tipo de gráfico a crear ('violin', 'scatter', 'bar', etc.).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if plot_type == 'violin':\n",
    "            # Violin plot\n",
    "            sns.violinplot(x=x, y=y, data=dataframe)\n",
    "            plt.xlabel(x)\n",
    "            plt.ylabel(y)\n",
    "            plt.title('Violin Plot')\n",
    "        \n",
    "        elif plot_type == 'scatter':\n",
    "            # Scatter plot\n",
    "            plt.scatter(dataframe[x], dataframe[y])\n",
    "            plt.xlabel(x)\n",
    "            plt.ylabel(y)\n",
    "            plt.title('Scatter Plot')\n",
    "        \n",
    "        elif plot_type == 'bar':\n",
    "            # Bar plot\n",
    "            sns.barplot(x=x, y=y, data=dataframe)\n",
    "            plt.xlabel(x)\n",
    "            plt.ylabel(y)\n",
    "            plt.title('Bar Plot')\n",
    "        \n",
    "        # Agregar más tipos de gráficos según sea necesario\n",
    "        \n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Ocurrió un error: {str(e)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"250\"></a> <br>\n",
    "### *Conclusiones*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se nos planteaba un interesante desafío, no solo en cuanto al contenido en sí, sino a la estructura y dinámica mismas del proyecto. Un trabajo en grupo, en un breve plazo de tiempo, con el fin de crear una completa y exhaustiva biblioteca de funciones en Python que resultaran útiles a cualquier persona que se dispusiera a enfrentarse a un proyecto de *machine learning*.\n",
    "\n",
    "Y sí demostró ser desafiante pero ampliamente valioso en cuanto a aprendizaje y coordinación. Es un proyecto que sin duda resulta beneficioso para desarrolladores y científicos de datos. Las funciones creadas y probadas nacen con la intención de ser reutilizables en cualquier proceso de implementación, y abarcan todas las etapas de un proyecto de aprendizaje automático, desde el preprocesamiento de los datos hasta la evaluación de los modelos, pasando por la visualización de datos y resultados.\n",
    "\n",
    "En definitiva, desde un punto de vista técnico y humano, esta biblioteca es, en sí misma, un instrumento de aprendizaje.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver al índice](#0)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
